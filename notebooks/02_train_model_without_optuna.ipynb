{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSDK_7Dj3YH9",
        "outputId": "1ddde303-c2e8-4612-8100-36cf689ffa7f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "quIhilm65orD",
        "outputId": "daf0111b-5a1f-4c55-95e2-d46b5143ee37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)\n",
            "Requirement already satisfied: lightgbm in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.6.0)\n",
            "Requirement already satisfied: mlflow<3 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.22.4)\n",
            "Requirement already satisfied: mlflow-skinny==2.22.4 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (2.22.4)\n",
            "Requirement already satisfied: Flask<4 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (3.1.2)\n",
            "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (3.1.6)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (1.17.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (3.4.3)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (3.10)\n",
            "Requirement already satisfied: matplotlib<4 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (3.10.8)\n",
            "Requirement already satisfied: numpy<3 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (2.2.6)\n",
            "Requirement already satisfied: pandas!=2.3.0,<3 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (2.3.3)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (19.0.1)\n",
            "Requirement already satisfied: scikit-learn<2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (1.7.2)\n",
            "Requirement already satisfied: scipy<2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (2.0.45)\n",
            "Requirement already satisfied: waitress<4 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow<3) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.1.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.74.0)\n",
            "Requirement already satisfied: fastapi<1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.124.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.39.1)\n",
            "Requirement already satisfied: packaging<25 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (6.33.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.12.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.28.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.5.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.38.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow<3) (1.3.10)\n",
            "Requirement already satisfied: tomli in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow<3) (2.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.22.4->mlflow<3) (0.4.6)\n",
            "Requirement already satisfied: google-auth~=2.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (2.45.0)\n",
            "Requirement already satisfied: pywin32>=304 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker<8,>=4.0.0->mlflow<3) (311)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker<8,>=4.0.0->mlflow<3) (1.26.12)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (0.50.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (0.0.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask<4->mlflow<3) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask<4->mlflow<3) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask<4->mlflow<3) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Flask<4->mlflow<3) (3.1.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (4.9.1)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from graphene<4->mlflow<3) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from graphene<4->mlflow<3) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from graphene<4->mlflow<3) (2.8.2)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.4->mlflow<3) (3.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<4->mlflow<3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<4->mlflow<3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<4->mlflow<3) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<4->mlflow<3) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<4->mlflow<3) (9.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<4->mlflow<3) (3.2.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.4->mlflow<3) (0.60b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.3.0,<3->mlflow<3) (2022.6)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.3.0,<3->mlflow<3) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow<3) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (2022.9.24)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn<2->mlflow<3) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn<2->mlflow<3) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow<3) (3.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (4.12.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\users\\91889\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn<1->mlflow-skinny==2.22.4->mlflow<3) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost lightgbm \"mlflow<3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRFqzWx-55CJ",
        "outputId": "c29141ec-c5ad-4588-c0df-e2cfe379a509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R:\\Downloads\\housing_app_fall25-main\\housing_app_fall25-main\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\91889\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "base_folder = \"R:\\\\Downloads\\\\housing_app_fall25-main\\\\housing_app_fall25-main\"\n",
        "%cd \"{base_folder}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "m1pqkWQ53TFh",
        "outputId": "070a405b-7ffb-4945-e9ce-723ddf5dda26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passenger_id</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Survived</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   passenger_id  Pclass   Age     Fare  SibSp  Parch  Survived     sex\n",
              "0             0       3  22.0   7.2500      1      0         0    male\n",
              "1             1       1  38.0  71.2833      1      0         1  female\n",
              "2             2       3  26.0   7.9250      0      0         1  female\n",
              "3             3       1  35.0  53.1000      1      0         1  female\n",
              "4             4       3  35.0   8.0500      0      0         0    male"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "conn = sqlite3.connect(f\"{base_folder}/data/titanic.db\")\n",
        "\n",
        "titanic = pd.read_sql_query(\n",
        "    \"\"\"\n",
        "    SELECT\n",
        "        p.passenger_id,\n",
        "        p.Pclass,\n",
        "        p.Age,\n",
        "        p.Fare,\n",
        "        ps.SibSp,\n",
        "        ps.Parch,\n",
        "        ps.Survived,\n",
        "        s.name AS sex\n",
        "    FROM passenger AS p\n",
        "    JOIN passenger_survival AS ps\n",
        "        ON ps.passenger_id = p.passenger_id\n",
        "    JOIN sex AS s\n",
        "        ON s.sex_id = p.sex_id\n",
        "    ORDER BY p.passenger_id\n",
        "    \"\"\",\n",
        "    conn,\n",
        ")\n",
        "\n",
        "conn.close()\n",
        "\n",
        "titanic.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exists: False\n",
            "URI: None\n",
            "USER: None\n",
            "PASS: MISSING\n",
            "Tracking URI: file:///R:/Downloads/housing_app_fall25-main/housing_app_fall25-main/mlruns\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import mlflow\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "env_path = Path.cwd() / \".env\"\n",
        "print(\"Exists:\", env_path.exists())\n",
        "\n",
        "load_dotenv(env_path, override=True)\n",
        "\n",
        "print(\"URI:\", os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "print(\"USER:\", os.getenv(\"MLFLOW_TRACKING_USERNAME\"))\n",
        "print(\"PASS:\", \"SET\" if os.getenv(\"MLFLOW_TRACKING_PASSWORD\") else \"MISSING\")\n",
        "\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTqNkkbR33iG",
        "outputId": "463058a0-4a86-4aa1-b191-dd24eb27442d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'R:\\Downloads\\housing_app_fall25-main\\housing_app_fall25-main\\mlruns\\1\\meta.yaml' does not exist.\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 329, in search_experiments\n",
            "    exp = self._get_experiment(exp_id, view_type)\n",
            "  File \"c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 427, in _get_experiment\n",
            "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
            "  File \"c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1373, in _read_yaml\n",
            "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
            "  File \"c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1366, in _read_helper\n",
            "    result = read_yaml(root, file_name)\n",
            "  File \"c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 310, in read_yaml\n",
            "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
            "mlflow.exceptions.MissingConfigException: Yaml file 'R:\\Downloads\\housing_app_fall25-main\\housing_app_fall25-main\\mlruns\\1\\meta.yaml' does not exist.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ STEP 1: Titanic preprocessing pipeline created.\n",
            "✓ STEP 2: Train=712, Test=179\n",
            "✓ STEP 3: Classification pipelines defined.\n",
            "✓ STEP 4: MLflow configured.\n",
            "\n",
            "================================================================================\n",
            "Training model: ridge\n",
            "================================================================================\n",
            "ridge CV F1:   0.7256\n",
            "ridge Test F1: 0.7287\n",
            "ridge Accuracy:0.8045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 317.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Training model: histgradientboosting\n",
            "================================================================================\n",
            "histgradientboosting CV F1:   0.7404\n",
            "histgradientboosting Test F1: 0.7669\n",
            "histgradientboosting Accuracy:0.8268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 458.90it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Training model: xgboost\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [17:26:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xgboost CV F1:   0.7429\n",
            "xgboost Test F1: 0.7353\n",
            "xgboost Accuracy:0.7989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 554.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Training model: lightgbm\n",
            "================================================================================\n",
            "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 208\n",
            "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
            "[LightGBM] [Info] Start training from score -0.475028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "lightgbm CV F1:   0.7387\n",
            "lightgbm Test F1: 0.7368\n",
            "lightgbm Accuracy:0.8045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 356.56it/s] \n",
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ STEP 5: Baseline models trained.\n",
            "\n",
            "================================================================================\n",
            "Training PCA model: ridge\n",
            "================================================================================\n",
            "ridge_with_pca Test F1: 0.7287\n",
            "\n",
            "================================================================================\n",
            "Training PCA model: histgradientboosting\n",
            "================================================================================\n",
            "histgradientboosting_with_pca Test F1: 0.7519\n",
            "\n",
            "================================================================================\n",
            "Training PCA model: xgboost\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [17:26:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xgboost_with_pca Test F1: 0.7259\n",
            "\n",
            "================================================================================\n",
            "Training PCA model: lightgbm\n",
            "================================================================================\n",
            "[LightGBM] [Info] Number of positive: 273, number of negative: 439\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1424\n",
            "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028\n",
            "[LightGBM] [Info] Start training from score -0.475028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "lightgbm_with_pca Test F1: 0.7338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\91889\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ STEP 6: PCA models trained.\n",
            "\n",
            "================================================================================\n",
            "GLOBAL BEST MODEL\n",
            "================================================================================\n",
            "Model: histgradientboosting\n",
            "Test F1: 0.7669\n",
            "✓ Global best model saved.\n",
            "Elapsed time: 49.61 seconds\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FULL PIPELINE (TITANIC CLASSIFICATION – FINAL WORKING VERSION)\n",
        "# =============================================================================\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "import mlflow\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Base folder (safe for VS Code / Jupyter)\n",
        "# ---------------------------------------------------------------------\n",
        "base_folder = (\n",
        "    Path.cwd().parent\n",
        "    if Path.cwd().name == \"notebooks\"\n",
        "    else Path.cwd()\n",
        ")\n",
        "\n",
        "start_time = time.monotonic()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: TITANIC PREPROCESSING PIPELINE (FIXES YOUR ERROR)\n",
        "# =============================================================================\n",
        "\n",
        "num_features = [\"Pclass\", \"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
        "cat_features = [\"sex\"]\n",
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "])\n",
        "\n",
        "preprocessing = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipeline, num_features),\n",
        "        (\"cat\", categorical_pipeline, cat_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"✓ STEP 1: Titanic preprocessing pipeline created.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: TRAIN / TEST SPLIT (STRATIFIED)\n",
        "# =============================================================================\n",
        "\n",
        "X = titanic.drop([\"passenger_id\", \"Survived\"], axis=1)\n",
        "y = titanic[\"Survived\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.20,\n",
        "    stratify=y,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(f\"✓ STEP 2: Train={len(X_train)}, Test={len(X_test)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: DEFINE CLASSIFICATION MODELS\n",
        "# =============================================================================\n",
        "\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "models = {\n",
        "    \"ridge\": RidgeClassifier(),\n",
        "    \"histgradientboosting\": HistGradientBoostingClassifier(),\n",
        "    \"xgboost\": XGBClassifier(\n",
        "        eval_metric=\"logloss\",\n",
        "        use_label_encoder=False\n",
        "    ),\n",
        "    \"lightgbm\": LGBMClassifier(),\n",
        "}\n",
        "\n",
        "pipelines = {\n",
        "    name: make_pipeline(preprocessing, model)\n",
        "    for name, model in models.items()\n",
        "}\n",
        "\n",
        "print(\"✓ STEP 3: Classification pipelines defined.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: CONFIGURE MLFLOW\n",
        "# =============================================================================\n",
        "\n",
        "load_dotenv(f\"{base_folder}\\\\notebooks\\\\.env\", override=True)\n",
        "\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "mlflow.set_experiment(\"titanic_survival_classification\")\n",
        "\n",
        "print(\"✓ STEP 4: MLflow configured.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: TRAIN & LOG MODELS (NO PCA)\n",
        "# =============================================================================\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"Training model: {name}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    cv_scores = cross_val_score(\n",
        "        pipeline,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=3,\n",
        "        scoring=\"f1\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    cv_f1 = cv_scores.mean()\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    test_f1 = f1_score(y_test, y_pred)\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        \"pipeline\": pipeline,\n",
        "        \"cv_f1\": cv_f1,\n",
        "        \"test_f1\": test_f1,\n",
        "    }\n",
        "\n",
        "    print(f\"{name} CV F1:   {cv_f1:.4f}\")\n",
        "    print(f\"{name} Test F1: {test_f1:.4f}\")\n",
        "    print(f\"{name} Accuracy:{test_acc:.4f}\")\n",
        "\n",
        "    with mlflow.start_run(run_name=f\"{name}_baseline\"):\n",
        "        mlflow.log_param(\"model_family\", name)\n",
        "        mlflow.log_param(\"uses_pca\", False)\n",
        "        mlflow.log_metric(\"cv_f1\", cv_f1)\n",
        "        mlflow.log_metric(\"test_f1\", test_f1)\n",
        "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
        "\n",
        "        signature = infer_signature(X_train, pipeline.predict(X_train))\n",
        "        mlflow.sklearn.log_model(\n",
        "            pipeline,\n",
        "            artifact_path=\"titanic_model\",\n",
        "            signature=signature,\n",
        "            input_example=X_train,\n",
        "        )\n",
        "\n",
        "print(\"\\n✓ STEP 5: Baseline models trained.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: PCA MODELS\n",
        "# =============================================================================\n",
        "\n",
        "pca_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"Training PCA model: {name}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    pca_pipeline = make_pipeline(\n",
        "        preprocessing,\n",
        "        PCA(n_components=0.95),\n",
        "        model,\n",
        "    )\n",
        "\n",
        "    cv_scores = cross_val_score(\n",
        "        pca_pipeline,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=3,\n",
        "        scoring=\"f1\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    cv_f1 = cv_scores.mean()\n",
        "\n",
        "    pca_pipeline.fit(X_train, y_train)\n",
        "    y_pred = pca_pipeline.predict(X_test)\n",
        "\n",
        "    test_f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    key = f\"{name}_with_pca\"\n",
        "    pca_results[key] = {\n",
        "        \"pipeline\": pca_pipeline,\n",
        "        \"cv_f1\": cv_f1,\n",
        "        \"test_f1\": test_f1,\n",
        "    }\n",
        "\n",
        "    print(f\"{key} Test F1: {test_f1:.4f}\")\n",
        "\n",
        "    with mlflow.start_run(run_name=key):\n",
        "        mlflow.log_param(\"model_family\", name)\n",
        "        mlflow.log_param(\"uses_pca\", True)\n",
        "        mlflow.log_metric(\"cv_f1\", cv_f1)\n",
        "        mlflow.log_metric(\"test_f1\", test_f1)\n",
        "\n",
        "print(\"\\n✓ STEP 6: PCA models trained.\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: SELECT GLOBAL BEST MODEL\n",
        "# =============================================================================\n",
        "\n",
        "all_results = {**results, **pca_results}\n",
        "best_name = max(all_results, key=lambda k: all_results[k][\"test_f1\"])\n",
        "best_pipeline = all_results[best_name][\"pipeline\"]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GLOBAL BEST MODEL\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Model: {best_name}\")\n",
        "print(f\"Test F1: {all_results[best_name]['test_f1']:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: SAVE BEST MODEL\n",
        "# =============================================================================\n",
        "\n",
        "os.makedirs(f\"{base_folder}/models\", exist_ok=True)\n",
        "joblib.dump(best_pipeline, f\"{base_folder}/models/global_best_model.pkl\")\n",
        "\n",
        "print(\"✓ Global best model saved.\")\n",
        "\n",
        "elapsed = time.monotonic() - start_time\n",
        "print(f\"Elapsed time: {elapsed:.2f} seconds\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
