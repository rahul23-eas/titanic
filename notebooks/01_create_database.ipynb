{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfaWlb492CvZ",
        "outputId": "74e2ca27-7257-41cc-e46a-14905665a684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R:\\Downloads\\housing_app_fall25-main\\housing_app_fall25-main\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\91889\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "base_folder = \"R:\\\\Downloads\\\\housing_app_fall25-main\\\\housing_app_fall25-main\"\n",
        "%cd \"{base_folder}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7rUZ8BQ2kYL",
        "outputId": "22263b6f-bdb4-4ab5-c885-3bac96812bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== BUILDING 3NF SQLITE DATA MODEL (TITANIC CLASSIFICATION) ===\n",
            "\n",
            "[STEP 1] Loading CSV into DataFrame…\n",
            "[1] Checking for titanic.tgz…\n",
            "[2] Extracting titanic.tgz…\n",
            "[3] Loading titanic.csv into DataFrame…\n",
            "Loaded 891 rows.\n",
            "\n",
            "[STEP 1a] Preparing target variable…\n",
            "\n",
            "[STEP 2] Creating surrogate key passenger_id…\n",
            "\n",
            "[STEP 3] Building sex dimension table…\n",
            "\n",
            "[STEP 4] Merging sex_id into main DataFrame…\n",
            "\n",
            "[STEP 5] Creating 3NF DataFrames…\n",
            "3NF DataFrames created.\n",
            "\n",
            "[STEP 6] Creating SQLite database and tables…\n",
            "Existing DB found. Removing…\n",
            "Tables created.\n",
            "\n",
            "[STEP 7] Inserting data into SQLite database…\n",
            "\n",
            "=== DONE! SQLite DB created at: ./data/titanic.db ===\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Base folder (safe for VS Code / Jupyter)\n",
        "# --------------------------------------------------\n",
        "base_folder = (\n",
        "    Path.cwd().parent\n",
        "    if Path.cwd().name == \"notebooks\"\n",
        "    else Path.cwd()\n",
        ")\n",
        "\n",
        "DATASETS_DIR = Path(\"datasets\")\n",
        "DATA_DIR = Path(f\"{base_folder}/data\")\n",
        "TARBALL_PATH = DATA_DIR / \"titanic.tgz\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Load Titanic data from titanic.tgz\n",
        "# --------------------------------------------------\n",
        "def load_titanic_data():\n",
        "    print(\"[1] Checking for titanic.tgz…\")\n",
        "    DATASETS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if not TARBALL_PATH.is_file():\n",
        "        print(\"[1a] File not found. Downloading titanic.tgz…\")\n",
        "        url = \"https://github.com/ageron/data/raw/main/titanic.tgz\"\n",
        "        urllib.request.urlretrieve(url, TARBALL_PATH)\n",
        "        print(\"[1b] Download completed.\")\n",
        "\n",
        "    print(\"[2] Extracting titanic.tgz…\")\n",
        "    with tarfile.open(TARBALL_PATH) as tar:\n",
        "        tar.extractall(path=DATASETS_DIR)\n",
        "\n",
        "    print(\"[3] Loading titanic.csv into DataFrame…\")\n",
        "    return pd.read_csv(DATASETS_DIR / \"titanic\" / \"titanic.csv\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Build 3NF SQLite Database (Classification)\n",
        "# --------------------------------------------------\n",
        "def build_3nf_sqlite(db_path=\"./data/titanic.db\"):\n",
        "    print(\"=== BUILDING 3NF SQLITE DATA MODEL (TITANIC CLASSIFICATION) ===\")\n",
        "\n",
        "    print(\"\\n[STEP 1] Loading CSV into DataFrame…\")\n",
        "    df = load_titanic_data()\n",
        "    print(f\"Loaded {len(df)} rows.\")\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # Classification target\n",
        "    # --------------------------------------------------\n",
        "    print(\"\\n[STEP 1a] Preparing target variable…\")\n",
        "    df = df.dropna(subset=[\"Survived\"])\n",
        "    df[\"Survived\"] = df[\"Survived\"].astype(int)\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # Surrogate key\n",
        "    # --------------------------------------------------\n",
        "    print(\"\\n[STEP 2] Creating surrogate key passenger_id…\")\n",
        "    df = df.reset_index().rename(columns={\"index\": \"passenger_id\"})\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # Dimension table: Sex\n",
        "    # --------------------------------------------------\n",
        "    print(\"\\n[STEP 3] Building sex dimension table…\")\n",
        "    sex_dim = (\n",
        "        df[[\"Sex\"]]\n",
        "        .drop_duplicates()\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    sex_dim[\"sex_id\"] = sex_dim.index + 1\n",
        "\n",
        "    print(\"\\n[STEP 4] Merging sex_id into main DataFrame…\")\n",
        "    df = df.merge(sex_dim, on=\"Sex\", how=\"left\")\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # 3NF DataFrames\n",
        "    # --------------------------------------------------\n",
        "    print(\"\\n[STEP 5] Creating 3NF DataFrames…\")\n",
        "\n",
        "    df_sex = sex_dim.rename(columns={\"Sex\": \"name\"})[\n",
        "        [\"sex_id\", \"name\"]\n",
        "    ]\n",
        "\n",
        "    df_passenger = df[\n",
        "        [\"passenger_id\", \"Pclass\", \"Age\", \"Fare\", \"sex_id\"]\n",
        "    ]\n",
        "\n",
        "    df_survival = df[\n",
        "        [\"passenger_id\", \"SibSp\", \"Parch\", \"Survived\"]\n",
        "    ]\n",
        "\n",
        "    print(\"3NF DataFrames created.\")\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # SQLite database\n",
        "    # --------------------------------------------------\n",
        "    print(\"\\n[STEP 6] Creating SQLite database and tables…\")\n",
        "    os.makedirs(\"./data\", exist_ok=True)\n",
        "\n",
        "    if os.path.exists(db_path):\n",
        "        print(\"Existing DB found. Removing…\")\n",
        "        os.remove(db_path)\n",
        "\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.executescript(\n",
        "        \"\"\"\n",
        "        DROP TABLE IF EXISTS passenger_survival;\n",
        "        DROP TABLE IF EXISTS passenger;\n",
        "        DROP TABLE IF EXISTS sex;\n",
        "\n",
        "        CREATE TABLE sex (\n",
        "            sex_id INTEGER PRIMARY KEY,\n",
        "            name TEXT NOT NULL UNIQUE\n",
        "        );\n",
        "\n",
        "        CREATE TABLE passenger (\n",
        "            passenger_id INTEGER PRIMARY KEY,\n",
        "            Pclass INTEGER NOT NULL,\n",
        "            Age REAL,\n",
        "            Fare REAL NOT NULL,\n",
        "            sex_id INTEGER NOT NULL,\n",
        "            FOREIGN KEY (sex_id)\n",
        "                REFERENCES sex(sex_id)\n",
        "        );\n",
        "\n",
        "        CREATE TABLE passenger_survival (\n",
        "            passenger_id INTEGER PRIMARY KEY,\n",
        "            SibSp INTEGER NOT NULL,\n",
        "            Parch INTEGER NOT NULL,\n",
        "            Survived INTEGER NOT NULL,\n",
        "            FOREIGN KEY (passenger_id)\n",
        "                REFERENCES passenger(passenger_id)\n",
        "        );\n",
        "        \"\"\"\n",
        "    )\n",
        "    print(\"Tables created.\")\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # Insert data\n",
        "    # --------------------------------------------------\n",
        "    print(\"\\n[STEP 7] Inserting data into SQLite database…\")\n",
        "\n",
        "    cur.executemany(\n",
        "        \"INSERT INTO sex VALUES (?, ?)\",\n",
        "        list(df_sex.itertuples(index=False, name=None)),\n",
        "    )\n",
        "\n",
        "    cur.executemany(\n",
        "        \"INSERT INTO passenger VALUES (?, ?, ?, ?, ?)\",\n",
        "        list(df_passenger.itertuples(index=False, name=None)),\n",
        "    )\n",
        "\n",
        "    cur.executemany(\n",
        "        \"INSERT INTO passenger_survival VALUES (?, ?, ?, ?)\",\n",
        "        list(df_survival.itertuples(index=False, name=None)),\n",
        "    )\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\n=== DONE! SQLite DB created at:\", db_path, \"===\\n\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# RUN\n",
        "# --------------------------------------------------\n",
        "build_3nf_sqlite()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
